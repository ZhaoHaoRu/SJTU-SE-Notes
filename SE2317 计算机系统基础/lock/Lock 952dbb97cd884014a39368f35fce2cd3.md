# Lock

### lock:

by putting a lock around a section of code, the programmer can guarantee that nomore than a single thread can ever be active within that code.

### **First Attempt: A Simple Flag:**

![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled.png)

- problems:
    - correctness: as below, *both* threads set the flag to 1 and both threads are thus able to enter the critical section.
    
    ![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled%201.png)
    
    - performance: the way a thread waits to acquire a lock that is already held: it endlessly checks the value of flag, a technique known as **spin-waiting**. Spin-waiting wastes time waiting for another thread to release a lock.

### **A Simple Spin Lock Using Test-and-set**

![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled%202.png)

![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled%203.png)

- When the thread calls TestAndSet(flag, 1), the routine will return the old value of flag, which is 0; thus, the calling thread, which is *testing* the value of flag, will not get caught spinning in the while loop and will acquire the lock. The thread will also atomically *set* the value to 1, thus indicating that the lock is now held. When the thread is fifinished with its critical section, it calls unlock() to set the flag back to zero.
- when one thread already has the lock held (i.e., flag is 1): this thread will spin and spin until the lock is finally released.
- Evaluating Spin Locks:
    - **correctness**: yes, the spin lock only allows a single thread to enter the critical section at a time. Thus, we have a correct lock.
    - **fairness:** Indeed, a thread spinning may spin forever, under contention. Simple spin locks (as discussed thus far) are not fair and may lead to starvation.
    - **performance:** in the single CPU case, performance overheads can be quite painful; where the thread holding the lock is preempted within a critical section. The scheduler might then run every other thread (imagine there are N 1 others), each of which tries to acquire the lock. In this case, each of those threads will spin for the duration of a time slice before giving up the CPU, a waste of CPU cycles.on multiple CPUs, spin locks work reasonably well.

### Compare-And-Swap

![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled%204.png)

![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled%205.png)

- 优点：减少了对内存的写的操作

### Load-Linked and Store-Conditional

![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled%206.png)

![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled%207.png)

- a thread spins waiting for the flag to be set to 0 (and thus indicate the lock is not held).
Once so, the thread tries to acquire the lock via the store-conditional; if it succeeds, the thread has atomically changed the flag’s value to 1 and thus can proceed into the critical section.
- two threads have each executed the load-linked and each are about to attempt the store conditional. The key feature of these instructions is that only one of these threads will succeed in updating the flag to 1 and thus acquire the lock; the second thread to attempt the store-conditional will fail (because the other thread updated the value of flag between its load-linked and storeconditional) and thus have to try to acquire the lock again.

### Fetch-And-Add

![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled%208.png)

![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled%209.png)

- when a thread wishes to acquire a lock, it first does an atomic fetch-and-add on the ticket value; that value is now considered this thread’s “turn” (myturn). The globally shared lock->turn is then used to determine which thread’s turn it is; when (myturn == turn) for a given thread, it is that thread’s turn to enter the critical section. Unlock is accomplished simply by incrementing the turn such that the next waiting thread (if there is one) can now enter the critical section.
- 优点：it ensures progress for all threads， Once a thread is assigned its ticket value, it will be scheduled at some point in the future (once those in front of it have passed through the critical section and released the lock).

> **Spin lock存在的关键问题：it wastes an entire time slice doing nothing but checking a value that isn’t going to change**
> 

### Yield

![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled%2010.png)

- A thread can be in one of three states (running, ready, or blocked); yield is simply a system call that moves the caller from the **running** state to the **ready** state, and thus promotes another thread to running. Thus, the yielding thread essentially **deschedules (调度)** itself.
- with two threads on one CPU：works quite well，If a thread happens to call lock() and find a lock held, it will simply yield the CPU, and thus the other thread will run and finish its critical section.
- many threads (say 100)：this approach is still costly; the cost of a **context switch** can be substantial, and there is thus plenty of waste.
- have not tackled the starvation problem at all

### Using Queues: Sleeping Instead Of Spinning

- former problem：they leave too much to chance. The scheduler determines which thread runs next; if the scheduler makes a bad choice, a thread runs that must either spin waiting for the lock (our first approach), or yield the CPU immediately (our second approach). we must explicitly exert some control over which thread next gets to acquire the lock after the current holder releases it.

![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled%2011.png)

![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled%2012.png)

- **park()** to put a calling thread to sleep, and **unpark(threadID)** to wake a particular thread as designated（指定的）by threadID.
- the flag does not get set back to 0 when another thread gets woken up：When a thread is woken up, it will be as if it is returning from park(); however, it does not hold the guard at that point in the code and thus cannot even try to set the flag to 1. Thus, we just pass the lock directly from the thread releasing the lock to the next thread acquiring it; flag is not set to 0 in-between.
- **wakeup/waiting race：** just before the call to park(). With just the wrong timing, a thread will
be about to park, assuming that it should sleep until the lock is no longer held. A switch at that time to another thread (say, a thread holding the lock) could lead to trouble, for example, if that thread then released the lock. The subsequent park by the first thread would then sleep forever
(potentially)
- setpark()：By calling this routine, a thread can indicate it is about to park. If it then happens to be interrupted and another thread calls unpark before park is actually called, the subsequent park returns immediately instead of sleeping：

![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled%2013.png)

### **Linux-based Futex Locks**

![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled%2014.png)

![Untitled](Lock%20952dbb97cd884014a39368f35fce2cd3/Untitled%2015.png)

- **futex wait(address, expected)：** puts the calling thread to sleep, assuming the value at address is equal to expected. If it is *not* equal, the call returns immediately.
- **futex_wake(address):** wakes one thread that is waiting on the queue
- it uses a single integer to track both whether the lock is held or not (the high bit of the integer) and the number of waiters on the lock (all the other bits). Thus, if the lock is negative, it is held (because the high bit is set and that bit determines the sign of the integer).
-